{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense,GlobalAveragePooling2D\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vmuser/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vggmodel = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(path):\n",
    "    img = image.load_img(path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return img, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'datasets/train'\n",
    "train_split, val_split = 0.9, 0.1\n",
    "\n",
    "categories = [x[0] for x in os.walk(root) if x[0]][1:]\n",
    "exclude = []\n",
    "categories = [c for c in categories if c not in [os.path.join(root, e) for e in exclude]]\n",
    "\n",
    "# print(categories)\n",
    "data = []\n",
    "for c, category in enumerate(categories):\n",
    "    images = [os.path.join(dp, f) for dp, dn, filenames \n",
    "              in os.walk(category) for f in filenames \n",
    "              if os.path.splitext(f)[1].lower() in ['.jpg','.png','.jpeg']]\n",
    "    for img_path in images:\n",
    "        img, x = get_image(img_path)\n",
    "        data.append({'x':np.array(x[0]), 'y':c})\n",
    "\n",
    "# count the number of classes\n",
    "num_classes = len(categories)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2065/2065 [==============================] - 813s 393ms/step - loss: 3.0028 - acc: 0.2191 - categorical_accuracy: 0.2191 - val_loss: 2.8181 - val_acc: 0.2540 - val_categorical_accuracy: 0.2540\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.25402, saving model to vgg16_1.h5\n",
      "Epoch 2/100\n",
      "2065/2065 [==============================] - 837s 405ms/step - loss: 2.7304 - acc: 0.2679 - categorical_accuracy: 0.2679 - val_loss: 2.6943 - val_acc: 0.2809 - val_categorical_accuracy: 0.2809\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.25402 to 0.28087, saving model to vgg16_1.h5\n",
      "Epoch 3/100\n",
      "2065/2065 [==============================] - 834s 404ms/step - loss: 2.6254 - acc: 0.2877 - categorical_accuracy: 0.2877 - val_loss: 2.6018 - val_acc: 0.2979 - val_categorical_accuracy: 0.2979\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.28087 to 0.29790, saving model to vgg16_1.h5\n",
      "Epoch 4/100\n",
      "2065/2065 [==============================] - 833s 403ms/step - loss: 2.5476 - acc: 0.3052 - categorical_accuracy: 0.3052 - val_loss: 2.5834 - val_acc: 0.3009 - val_categorical_accuracy: 0.3009\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.29790 to 0.30087, saving model to vgg16_1.h5\n",
      "Epoch 5/100\n",
      "2065/2065 [==============================] - 828s 401ms/step - loss: 2.4841 - acc: 0.3155 - categorical_accuracy: 0.3155 - val_loss: 2.5923 - val_acc: 0.3008 - val_categorical_accuracy: 0.3008\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.30087\n",
      "Epoch 6/100\n",
      "2065/2065 [==============================] - 826s 400ms/step - loss: 2.4282 - acc: 0.3287 - categorical_accuracy: 0.3287 - val_loss: 2.5589 - val_acc: 0.3079 - val_categorical_accuracy: 0.3079\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.30087 to 0.30790, saving model to vgg16_1.h5\n",
      "Epoch 7/100\n",
      "2065/2065 [==============================] - 825s 400ms/step - loss: 2.3680 - acc: 0.3394 - categorical_accuracy: 0.3394 - val_loss: 2.5454 - val_acc: 0.3066 - val_categorical_accuracy: 0.3066\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.30790\n",
      "Epoch 8/100\n",
      "2065/2065 [==============================] - 826s 400ms/step - loss: 2.3179 - acc: 0.3506 - categorical_accuracy: 0.3506 - val_loss: 2.5393 - val_acc: 0.3135 - val_categorical_accuracy: 0.3135\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.30790 to 0.31353, saving model to vgg16_1.h5\n",
      "Epoch 9/100\n",
      "2065/2065 [==============================] - 820s 397ms/step - loss: 2.2628 - acc: 0.3637 - categorical_accuracy: 0.3637 - val_loss: 2.5496 - val_acc: 0.3163 - val_categorical_accuracy: 0.3163\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.31353 to 0.31632, saving model to vgg16_1.h5\n",
      "Epoch 10/100\n",
      "2065/2065 [==============================] - 819s 397ms/step - loss: 2.2086 - acc: 0.3739 - categorical_accuracy: 0.3739 - val_loss: 2.5573 - val_acc: 0.3187 - val_categorical_accuracy: 0.3187\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.31632 to 0.31869, saving model to vgg16_1.h5\n",
      "Epoch 11/100\n",
      "1971/2065 [===========================>..] - ETA: 29s - loss: 2.1504 - acc: 0.3857 - categorical_accuracy: 0.3857"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiahao/anaconda3/envs/tensorflow_gpu/lib/python3.6/site-packages/keras/utils/data_utils.py:610: UserWarning: The input 1787 could not be retrieved. It could be because a worker has died.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# vggmodel.summary()\n",
    "\n",
    "num_class = np.unique(testdata.classes).shape[0]\n",
    "\n",
    "\n",
    "x=vggmodel.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
    "x=Dense(512,activation='relu')(x) #dense layer 3\n",
    "\n",
    "preds = Dense(num_class, activation=\"softmax\")(x)\n",
    "model_final = Model(inputs = vggmodel.input, outputs = preds)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for layer in model_final.layers[:20]:\n",
    "    layer.trainable=False\n",
    "for layer in model_final.layers[20:]:\n",
    "    layer.trainable=True\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "model_final.compile(loss = \"categorical_crossentropy\", \n",
    "                    optimizer = 'Adam', metrics=[\"accuracy\",\"categorical_accuracy\"])\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1,\n",
    "                             save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=40, verbose=1, mode='auto')\n",
    "\n",
    "\n",
    "model_final.fit_generator(generator= traindata, steps_per_epoch= 2065, epochs= 100,\n",
    "                          validation_data= testdata, validation_steps=0, callbacks=[checkpoint,early])\n",
    "\n",
    "model_final.save_weights(\"vgg16_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vggmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = np.unique(testdata.classes).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-snake] *",
   "language": "python",
   "name": "conda-env-.conda-snake-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
