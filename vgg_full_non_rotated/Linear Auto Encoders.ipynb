{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/jiahao/anaconda3/envs/tensorflow_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jiahao/anaconda3/envs/tensorflow_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jiahao/anaconda3/envs/tensorflow_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jiahao/anaconda3/envs/tensorflow_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jiahao/anaconda3/envs/tensorflow_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jiahao/anaconda3/envs/tensorflow_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "from tensorflow.python.ops import data_flow_ops\n",
    "from sklearn import metrics\n",
    "from scipy.optimize import brentq\n",
    "from scipy import interpolate\n",
    "import argparse\n",
    "import imageio as io\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImage(imagepath):\n",
    "    im =  None\n",
    "    try:\n",
    "        image = Image.open(imagepath)\n",
    "        image.copy().verify()\n",
    "        im = np.asarray(image)\n",
    "    except (IOError,SyntaxError) as e:\n",
    "        print('Bad file:', imagepath)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_info(imageDir):\n",
    "    all_imagesid = []\n",
    "    all_image_paths = []\n",
    "    count = 0 \n",
    "    for name in os.listdir(imageDir):\n",
    "        curr_id_images = []\n",
    "        for curr_image in os.listdir(imageDir + \"/\" + name):\n",
    "            curr_path = imageDir + \"/\" + name + \"/\" + curr_image\n",
    "            curr_id_images.append(curr_path)\n",
    "        for p_pos in range(0,len(curr_id_images)):\n",
    "            all_imagesid.append(name)\n",
    "            all_image_paths.append(curr_id_images[p_pos])\n",
    "    return all_image_paths,all_imagesid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_matrix(all_imagesdir,batchsize,startpoint):\n",
    "    count = 0\n",
    "    data_matrix = []\n",
    "    for i in range(batchsize):\n",
    "        new_image = readImage(all_imagesdir[startpoint])\n",
    "        if new_image is not None:\n",
    "            new_image = np.ndarray.flatten(np.array(Image.fromarray(new_image).resize((200,200),Image.BILINEAR))/255.)\n",
    "            if count == 0:\n",
    "                data_matrix = new_image \n",
    "                count += 1\n",
    "            else:\n",
    "                data_matrix = np.vstack((data_matrix,new_image))\n",
    "        startpoint +=1\n",
    "        \n",
    "    \n",
    "    return data_matrix,startpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesDir = 'round1_test'\n",
    "all_image_paths,all_imagesid = get_images_info(imagesDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100\n",
      "Bad file: round1_test/round1/773a7c1b0904561126a608f5fac2a3f8.jpg\n",
      "Bad file: round1_test/round1/2b8060650fbc5c4d04c831e37b6a2af3.jpg\n",
      "Bad file: round1_test/round1/88277e9b21c88548fb99eb32d46b440a.jpg\n",
      "Bad file: round1_test/round1/142f43fd0a314ecd7f3e4cbfc1f3080c.jpg\n",
      "Batch 14/14 e list check point: 2100\n",
      "epoch 1 loss 0.18226280808448792\n",
      "Epoch: 2/100\n",
      "Bad file: round1_test/round1/2b8060650fbc5c4d04c831e37b6a2af3.jpg\n",
      "Bad file: round1_test/round1/f5fe0394d7732da1ce5373133e275874.jpg\n",
      "Bad file: round1_test/round1/7ae396c98d9cf5a4927f89a48be1b027.jpg\n",
      "Batch 14/14 e list check point: 2100\n",
      "epoch 2 loss 0.1852658987045288\n",
      "Epoch: 3/100\n",
      "Bad file: round1_test/round1/094684c7f05726dcf48edd40f521de12.jpg\n",
      "Bad file: round1_test/round1/f8675f96b7b71c2c615fc31ca79fd98d.jpg\n",
      "Bad file: round1_test/round1/b099b295efe26cec8064600a6ca5cd97.jpg\n",
      "Bad file: round1_test/round1/d52ebe0861059d04c0ea16acbbf47648.jpg\n",
      "Bad file: round1_test/round1/035b83d6eb12ca399d5fb7a5a4f5b73b.jpg\n",
      "Batch 14/14 e list check point: 2100\n",
      "epoch 3 loss 0.19647005200386047\n",
      "Epoch: 4/100\n",
      "Bad file: round1_test/round1/b59cbae57050c1b65130c79971309caf.jpg\n",
      "Bad file: round1_test/round1/8c57224e5d5d4d76b34f4c467e6c6c73.jpg\n",
      "Batch 14/14 e list check point: 2100\n",
      "epoch 4 loss 0.18583464622497559\n",
      "Epoch: 5/100\n",
      "Bad file: round1_test/round1/bd8e2d98c306b0118abe5294bde8a063.jpg\n",
      "Bad file: round1_test/round1/a781d33863fa2eb233b366982fc311f2.jpg\n",
      "Bad file: round1_test/round1/a7775e93e11bcb9de449b40742fb922f.jpg\n",
      "Batch 14/14 e list check point: 2100\n",
      "epoch 5 loss 0.19190557301044464\n",
      "Epoch: 6/100\n",
      "Bad file: round1_test/round1/7ae396c98d9cf5a4927f89a48be1b027.jpg\n",
      "Bad file: round1_test/round1/1609b108e31ccb318ee8e475ca72074e.jpg\n",
      "Bad file: round1_test/round1/bd8e2d98c306b0118abe5294bde8a063.jpg\n",
      "Bad file: round1_test/round1/142f43fd0a314ecd7f3e4cbfc1f3080c.jpg\n",
      "Bad file: round1_test/round1/f036432c65478a29ffc288c50c2c862f.jpg\n",
      "Batch 14/14 e list check point: 2100\n",
      "epoch 6 loss 0.18507620692253113\n",
      "Epoch: 7/100\n",
      "Bad file: round1_test/round1/e21b308876dd40450fd79befadf72e84.jpg\n",
      "Bad file: round1_test/round1/bd8e2d98c306b0118abe5294bde8a063.jpg\n",
      "Batch 5/14 ge list check point: 750\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ed397e9ffd62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_image_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstartpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_images_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_image_paths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstartpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Current image list check point: %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstartpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-a59bac21b859>\u001b[0m in \u001b[0;36mget_images_matrix\u001b[0;34m(all_imagesdir, batchsize, startpoint)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mnew_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_imagesdir\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstartpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_image\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mnew_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBILINEAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mdata_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpu/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box)\u001b[0m\n\u001b[1;32m   1890\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1892\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1894\u001b[0m     def rotate(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "num_inputs=200*200*3    #80x80x3 pixels\n",
    "num_hid1=512\n",
    "num_output=num_inputs\n",
    "lr=0.0033\n",
    "\n",
    "activation_func=tf.nn.relu\n",
    "\n",
    "X=tf.placeholder(tf.float32,shape=[None,num_inputs])\n",
    "initializer=tf.variance_scaling_initializer()\n",
    "\n",
    "w1=tf.Variable(initializer([num_inputs,num_hid1]),dtype=tf.float32)\n",
    "w2=tf.Variable(initializer([num_hid1,num_output]),dtype=tf.float32)\n",
    "b1=tf.Variable(tf.zeros(num_hid1))\n",
    "b2=tf.Variable(tf.zeros(num_output))\n",
    "hid_layer1= activation_func(tf.matmul(X,w1)+b1)\n",
    "output_layer= activation_func(tf.matmul(hid_layer1,w2)+b2)\n",
    "\n",
    "\n",
    "loss=tf.reduce_mean(tf.square(output_layer-X))\n",
    "optimizer=tf.train.RMSPropOptimizer(lr, decay=0.9, momentum=0.9, epsilon=1.0)\n",
    "train=optimizer.minimize(loss)\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "num_epoch=100\n",
    "batch_size=150\n",
    "num_test_images=10\n",
    "startpoint = 0 \n",
    "\n",
    "# test_imagesDir = 'datasets/all_faces_data_randomized'\n",
    "# all_test_paths,all_test_id = get_images_info(test_imagesDir)\n",
    "# #test_data_mat = get_test_images_matrix(all_test_paths,10)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(num_epoch):\n",
    "        num_batches= len(all_image_paths)//batch_size\n",
    "        print(\"Epoch: %d/%d\" %(epoch+1,num_epoch))\n",
    "        np.random.shuffle(all_image_paths)\n",
    "        for iteration in range(num_batches):\n",
    "            X_batch,startpoint = get_images_matrix(all_image_paths,batch_size,startpoint)\n",
    "            print(\"Current image list check point: %d\" %(startpoint),end = '\\r')\n",
    "            sess.run(train,feed_dict={X:X_batch})\n",
    "            print(\"Batch %d/%d \"%(iteration+1,num_batches), end = '\\r')     \n",
    "        startpoint = 0\n",
    "        print(\"\")\n",
    "        train_loss=loss.eval(feed_dict={X:X_batch})\n",
    "        print(\"epoch {} loss {}\".format(epoch+1,train_loss))\n",
    "        if epoch % 5 == 0 :\n",
    "            saver.save(sess, \"autoencoder_model/model-%d.ckpt\" %(epoch))\n",
    "        with open(('autoencoder_model/auto_encoder_mse.txt'),'at') as f:\n",
    "            f.write('%2.5f\\n'%(train_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restoring point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch=3\n",
    "batch_size=150\n",
    "num_test_images=10\n",
    "startpoint = 0 \n",
    "\n",
    "test_imagesDir = 'datasets/all_faces_data_randomized'\n",
    "all_test_paths,all_test_id = get_images_info(test_imagesDir)\n",
    "#test_data_mat = get_test_images_matrix(all_test_paths,10)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"autoencoder_model/model-40.ckpt\")\n",
    "    for epoch in range(num_epoch):\n",
    "        num_batches= len(all_image_paths)//batch_size\n",
    "        print(\"Epoch: %d/%d\" %(epoch+1,num_epoch))\n",
    "        for iteration in range(num_batches):\n",
    "            X_batch,startpoint = get_images_matrix(all_image_paths,batch_size,startpoint)\n",
    "            sess.run(train,feed_dict={X:X_batch})\n",
    "            print(\"Batch %d/%d \"%(iteration+1,num_batches), end = '\\r')\n",
    "            \n",
    "        \n",
    "        startpoint = 0\n",
    "        print(\"\")\n",
    "        train_loss=loss.eval(feed_dict={X:X_batch})\n",
    "        print(\"epoch {} loss {}\".format(epoch,train_loss))\n",
    "        saver.save(sess, \"autoencoder_cont/model-%d.ckpt\" %(epoch))\n",
    "        with open(('autoencoder_cont/auto_encoder_mse.txt'),'at') as f:\n",
    "            f.write('%2.5f\\n'%(average_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_gpu] *",
   "language": "python",
   "name": "conda-env-tensorflow_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
